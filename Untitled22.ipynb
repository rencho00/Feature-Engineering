{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(target_col):\n",
    "    elements, counts = np.unique(target_col,return_counts = True)\n",
    "    entropy = np.sum( [(-counts[i]/np.sum(counts))* np.log2(counts[i]/np.sum(counts)) for i range(len(elements))])\n",
    "    return entropy\n",
    "\n",
    "def InfoGain(data,split_attribute_name,target_name = 'class'):\n",
    "    \n",
    "    total_entropy = entropy(data[target_name])\n",
    "    \n",
    "    vals,counts = np.unique(data[split_attribute_name], return_counts = True)\n",
    "    \n",
    "    Weighted_entropy = np.sum([(counts[i] / np.sum(counts)) * entropy(data.where \n",
    "                                                                      \n",
    "                        (data[split_attribute_name]= vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
    "    \n",
    "    Information_gain = total_entropy - Weighted_Entropy\n",
    "    \n",
    "    return Information_gain\n",
    "\n",
    "def ID3(data,originaldata, features, target_attribute_name = 'class', parent_node_class = None ):\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "    \n",
    "    elif len(data) == 0:\n",
    "        return np.unique( originaldata[target_attribute_name]) [np.argmax(np.unique(originaldata[taget_attribute_name]\n",
    "                                                                                     \n",
    "                                    , return_counts = True )[1])]\n",
    "    \n",
    "    elif len(features) == 0:\n",
    "        return parent_node_class\n",
    "    \n",
    "    else:\n",
    "        parent_node_class = np.unique(data[target_attribute_name]) [np.argmax(np.unique(data[target_attribute_name]\n",
    "                                                                                       \n",
    "                                            ,return_counts = True)[1])]\n",
    "        \n",
    "        item_values = [InfoGain(data,feature, target_attribute_name) for feature in features ]\n",
    "        \n",
    "        best_feature_index = np.argmax(item_values)\n",
    "        \n",
    "        best_feature = features[ best_feature_index]\n",
    "        \n",
    "        tree = {best_feature : {}}\n",
    "        \n",
    "        features = [i for i in feature if i != best_feature ]\n",
    "        \n",
    "        for value in np.unique(data[best_feature]):\n",
    "            \n",
    "            sub_data=data.where(data[beat_feature] == value ).dropna()\n",
    "            \n",
    "            subtree = ID3(sub_data, dataset, features, target_attribute_name, parent_node_class )\n",
    "            \n",
    "            tree[best_feature][vale] = subtree\n",
    "            \n",
    "        return(tree)\n",
    "    \n",
    "def predict(query, tree, default =  1):\n",
    "    \n",
    "    for key in list(query.key()) :\n",
    "        if key in list(tree.keys()):\n",
    "            \n",
    "            try:\n",
    "                result = tree[key][query[key]]\n",
    "                \n",
    "            except:\n",
    "                return default\n",
    "            \n",
    "            if isinstance(result, dict):\n",
    "                return predict(query, result)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                return result\n",
    "            \n",
    "def train_test_split(datset):\n",
    "    \n",
    "    training_data = dataset.iloc[:80].reset_index(drop = True)\n",
    "    \n",
    "    testing_data = dataset.iloc[80:].reset_index (drop = True)\n",
    "    \n",
    "    return training_data, testing_data \n",
    "\n",
    "training_data = train_test_split(dataset)[0]\n",
    "testing_data = train_test_split(dataset)[0]\n",
    "\n",
    "def test(data,tree):\n",
    "    \n",
    "    queries = data.iloc[:,:-1].to_dict(orient = 'records')\n",
    "    \n",
    "    predicted = pd.DataFrame(columns= ['predicted'])\n",
    "    \n",
    "    for in in range(len(data)):\n",
    "        \n",
    "        predicted.loc[i,'predicted'] = predict(queries[i], tree, 1.0)\n",
    "    print( \"The prediction accuracy is :\", (np.sum(predicted['predicted'] == data['class'])/len(data))*10, %)\n",
    "        \n",
    "\n",
    "tree = ID3(training_data, training_data, training_data.columns[:-1])\n",
    "\n",
    "pprint(tree)\n",
    "test(testing_data,tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
